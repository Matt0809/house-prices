{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A complete pipeline for pulling current properties from Zoopla, adding commute times to two workplaces using Google Maps API, scraping extra information from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All imports\n",
    "\"\"\"\n",
    "\n",
    "import zoopla # Python wrapper for Zoopla API. Installed through pip.\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x,'display.max_columns', None, 'display.max_rows', None)\n",
    "\n",
    "# To get latest file in| directory\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "from time import sleep\n",
    "import googlemaps # Python wrapper for Google Maps API. Installed through pip.\n",
    "import time\n",
    "\n",
    "# Beautiful soup for web scraping\n",
    "import requests\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "# For simple linear regression on area values\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoopla Property Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "API keys\n",
    "\"\"\"\n",
    "\n",
    "current = []  # List to assist in deleting old listings\n",
    "c=0 # Counter \n",
    "api = {'API_1':'...','API_2':'...'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Search parameters. Needs to be in the form of a radius from a certain point, so here it is set to Waterloo Stations lat/long, with a 20 mile radius\n",
    "\"\"\"\n",
    "\n",
    "params = {  'maximum_beds': 2,\n",
    "            'page_size': 100,\n",
    "            'page_number': 1,\n",
    "            'listing_status': 'sale',\n",
    "            'latitude': '51.5032',\n",
    "            'longitude': '-0.1123',\n",
    "            'radius': 20,\n",
    "            'maximum_price': 400000,\n",
    "            'minimum_price': 250000,\n",
    "            'order_by': 'age',\n",
    "            'ordering': 'descending'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ONLY NEEDS TO BE RUN IF LOADING FROM PREVIOUS FILE\n",
    "\"\"\"\n",
    "\n",
    "# Script to join full search with < 60 minutes subsection before updating (to save appending Google Maps and all other data again). \n",
    "\n",
    "# latest full\n",
    "list_of_files = glob.glob('.../gmaps/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file,index_col=0)\n",
    "# df = df.transpose()\n",
    "df = df.drop(['agent_address','agent_logo','category','country','country_code','image_url','street_name'],axis=1) \n",
    "\n",
    "# latest subsection\n",
    "list_of_files = glob.glob('.../final/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "d2 = pd.read_csv(latest_file,index_col=0) \n",
    "\n",
    "print \"df shape: \",df.shape\n",
    "print \"d2 shape: \",d2.shape\n",
    "\n",
    "# Combines subsection with extra details with full set containing all distances for comparison against new search. Leaves duplicates of subsection, one old without extra details e.g. zed index and one with.\n",
    "d3 = df.merge(d2, on=df.columns.tolist(),how='outer')\n",
    "print \"original d3 shape: \",d3.shape\n",
    "\n",
    "# Sort zed index to place filled subsection first, then delete the empty subsection to deduplicate\n",
    "d3 = d3.sort_values('zed_index')\n",
    "d3['listing_id'] = d3['listing_id'].astype('int')\n",
    "d3['listing_id'] = d3['listing_id'].astype('string')\n",
    "d3 = d3.drop_duplicates(subset='listing_id',keep='first')\n",
    "print \"deduplicated d3 shape: \",d3.shape\n",
    "d3 = d3.set_index('listing_id',drop=False)\n",
    "del d3.index.name\n",
    "now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "d3.to_csv(\".../join/\"+str(now)+\".csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Won't work if > 20,000 results - max limit 10,000 (page num 100 * page size 100) for each API key.\n",
    "Luckily within my search parameters there are roughly 13,000 results, so I am able to order by ascending with one API key then descending to get the remaining 3,000.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# From scratch\n",
    "l = {}\n",
    "\n",
    "# Reads file from previous run\n",
    "\n",
    "# list_of_files = glob.glob('.../join/*')\n",
    "# latest_file = max(list_of_files, key=os.path.getctime)\n",
    "# df = pd.read_csv(latest_file,index_col=0)\n",
    "# df.index = df.index.astype('string')\n",
    "# df = df.transpose()\n",
    "# l = df.to_dict()\n",
    "\n",
    "\n",
    "class GetOutOfLoop( Exception ):\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    try:\n",
    "        zoop = zoopla.Zoopla(api_key=api['API_1'])\n",
    "        search = zoop.property_listings(params)\n",
    "        while len(search.listing) != 0:\n",
    "            print \"Page number: \",params['page_number']\n",
    "            print \"Result count : \",search.result_count\n",
    "            print \"API_1\"\n",
    "            search = zoop.property_listings(params)\n",
    "            for i in range(len(search.listing)):\n",
    "                if search.listing[i].listing_id in current:\n",
    "                    pass\n",
    "                else:\n",
    "                    current.append(search.listing[i].listing_id)\n",
    "                if search.listing[i].listing_id in l.keys():\n",
    "                    c+=1\n",
    "                else:\n",
    "                    l[search.listing[i].listing_id]=search.listing[i]\n",
    "            params['page_number']+=1\n",
    "        else:\n",
    "            raise GetOutOfLoop\n",
    "        \n",
    "    except zoopla.exceptions.ZooplaAPIException: \n",
    "        if params['page_number'] < 100:\n",
    "            print \"API_1 Page number \",params['page_number'], \" less than expected. API limit reached, waiting until next full hour.\"\n",
    "            now = datetime.datetime.now()\n",
    "            h = int(now.strftime(\"%H\"))+1\n",
    "            t = now.replace(hour=h,minute=0,second=0)\n",
    "            wait = t - now\n",
    "            print \"Waiting for \",wait.seconds/60,\" minutes.\"\n",
    "            sleep(wait.seconds)\n",
    "            pass \n",
    "        \n",
    "        try:\n",
    "            zoop = zoopla.Zoopla(api_key=api['API_2'])\n",
    "            params['ordering']='ascending'\n",
    "            params['page_number']=1\n",
    "            while len(search.listing) != 0:\n",
    "                print \"Page number: \",params['page_number']\n",
    "                print \"Result count : \",search.result_count\n",
    "                print \"API_2\"\n",
    "                search = zoop.property_listings(params)\n",
    "                for i in range(len(search.listing)):\n",
    "                    if search.listing[i].listing_id in current:\n",
    "                        pass\n",
    "                    else:\n",
    "                        current.append(search.listing[i].listing_id)\n",
    "                    if search.listing[i].listing_id in l.keys():\n",
    "                        c+=1\n",
    "                    else:\n",
    "                        l[search.listing[i].listing_id]=search.listing[i]\n",
    "                params['page_number']+=1\n",
    "            else:\n",
    "                raise GetOutOfLoop\n",
    "                \n",
    "        except zoopla.exceptions.ZooplaAPIException:\n",
    "            if params['page_number'] < 100:\n",
    "                print \"API_2 Page number \",params['page_number'], \" less than expected. API limit reached, waiting until next full hour.\"\n",
    "                now = datetime.datetime.now()\n",
    "                h = int(now.strftime(\"%H\"))+1\n",
    "                t = now.replace(hour=h,minute=0,second=0)\n",
    "                wait = t - now\n",
    "                print now\n",
    "                print \"Waiting for \",wait.seconds/60,\" minutes.\"\n",
    "                sleep(wait.seconds)\n",
    "                pass\n",
    "            \n",
    "except GetOutOfLoop:\n",
    "    print \"Reached end.\"\n",
    "    pass      \n",
    "\n",
    "for x in l.keys():\n",
    "    if x in current:\n",
    "        pass\n",
    "    else:\n",
    "        l.pop(x, None)\n",
    "    \n",
    "print \"Finished both 10,000 cycles.\"\n",
    "print \"Added \", search.result_count - c\n",
    "print \"Length l: \",len(l)\n",
    "\n",
    "# Save dictionary using pandas\n",
    "now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "print str(datetime.datetime.now())\n",
    "df = df.from_dict(l)\n",
    "df = df.transpose()\n",
    "df.to_csv(\".../Zoopla/\"+str(now)+\".csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checks difference in new property listings\n",
    "\"\"\"\n",
    "\n",
    "list_of_files = glob.glob('.../join/*') # Old\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file,index_col=0)\n",
    "# df = df.transpose()\n",
    "\n",
    "list_of_files = glob.glob('.../Zoopla/*') # New\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "d2 = pd.read_csv(latest_file,index_col=0)\n",
    "# d2 = d2.transpose()\n",
    "\n",
    "print \"df shape: \",df.shape\n",
    "print \"d2 shape: \",d2.shape\n",
    "dfi = df.index.tolist()\n",
    "d2i = d2.index.tolist()\n",
    "dfi = [str(i) for i in dfi]\n",
    "d2i = [str(i) for i in d2i]\n",
    "print dfi[:5]\n",
    "print d2i[:5]\n",
    "print \"Difference: \", len(set(dfi).symmetric_difference(set(d2i)))\n",
    "new = set(dfi)-set(d2i)\n",
    "print \"Length: new \",len(new)\n",
    "\n",
    "# print new\n",
    "old = set(d2i)-set(dfi)\n",
    "print \"Length: old \",len(old)\n",
    "\n",
    "# print old\n",
    "now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "new_df = pd.DataFrame(list(new))\n",
    "new_df.to_csv(\".../new/\"+str(now)+\".csv\",encoding='utf-8',header=False,index=False)\n",
    "print \"Written new list.\" # This is used to conditionally format spreadsheet with new properties this run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adds google maps times to zoopla property listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t can only be 8 days in the past.\n",
    "t = datetime.datetime(2018,4,16,9)\n",
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_work_1(address):\n",
    "    directions_result = gmaps.directions(address,\n",
    "                                         \"...\",\n",
    "                                         mode=\"transit\",\n",
    "                                         arrival_time=t)\n",
    "    try:\n",
    "        a = directions_result[0][\"legs\"][0][\"duration\"][\"text\"]\n",
    "        return convert_to_mins(a)\n",
    "    except IndexError:\n",
    "        print \"Address empty             \", address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_work_2(address):\n",
    "    directions_result = gmaps.directions(address,\n",
    "                                         \"...\",\n",
    "                                         mode=\"transit\",\n",
    "                                         arrival_time=t)\n",
    "    try:\n",
    "        a = directions_result[0][\"legs\"][0][\"duration\"][\"text\"]\n",
    "        return convert_to_mins(a)\n",
    "    except IndexError:\n",
    "        print \"Address empty             \", address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycling_work_2(address):\n",
    "    directions_result = gmaps.directions(address,\n",
    "                                         \"...\",\n",
    "                                         mode=\"bicycling\",\n",
    "                                         arrival_time=t)\n",
    "    try:\n",
    "        a = directions_result[0][\"legs\"][0][\"duration\"][\"text\"]\n",
    "        return convert_to_mins(a)\n",
    "    except IndexError:\n",
    "        print \"Address empty             \", address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mins(s):\n",
    "    if len(str(s).split(\" \"))==2:\n",
    "        return int(s.split(\" \")[0])\n",
    "    if len(str(s).split(\" \"))==4:\n",
    "        return int(s.split(\" \")[0])*60 + int(s.split(\" \")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Google Maps API's\n",
    "\"\"\"\n",
    "\n",
    "gmapsAPI = {'API_1':'...', 'API_2':'...'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adds commute times\n",
    "\"\"\"\n",
    "\n",
    "# Reads file from previous run\n",
    "list_of_files = glob.glob('.../Zoopla/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file, index_col=0)\n",
    "df = df.transpose()\n",
    "l = df.to_dict()\n",
    "\n",
    "c = 0\n",
    "written = 0\n",
    "passed = 0\n",
    "\n",
    "a = 0 # API key list iterator\n",
    "a_list = ['gmaps_API_1', 'gmaps_API_2']\n",
    "gmaps = googlemaps.Client(key=gmapsAPI[a_list[a]])\n",
    "\n",
    "class GetOutOfLoop( Exception ):\n",
    "    pass\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "try:\n",
    "    for i in l.keys():\n",
    "        print c\n",
    "        c+=1\n",
    "        address = l[i]['displayable_address']\n",
    "        length = len(address.split(\",\"))\n",
    "        while True:\n",
    "            try:\n",
    "                if any( [ l[i]['distance_work_1'] != l[i]['distance_work_1'], \n",
    "                          l[i]['distance_work_2'] != l[i]['distance_work_2'],\n",
    "                          l[i]['distance_work_1'] == l[i]['distance_work_2'],\n",
    "                          any(x not in l[i].keys() for x in ['distance_work_1','distance_work_2']) ] ):\n",
    "                    if l[i]['distance_work_1'] == l[i]['distance_work_2']:\n",
    "                        for x in range(length):\n",
    "                            try:\n",
    "                                l[i]['distance_work_2'] = distance_work_2(','.join(address.split(\",\")[x:]))\n",
    "                            except (googlemaps.exceptions.ApiError, IndexError, TypeError) as e:\n",
    "                                print \"Address failed:          \", ','.join(address.split(\",\")[x:])\n",
    "                            else:\n",
    "                                written += 1\n",
    "                                break\n",
    "                    else:\n",
    "                        for x in range(length):\n",
    "                            try:\n",
    "                                l[i]['distance_work_1'] = distance_work_1(','.join(address.split(\",\")[x:]))\n",
    "                            except (googlemaps.exceptions.ApiError, IndexError, TypeError) as e:\n",
    "                                print \"Address failed:          \", ','.join(address.split(\",\")[x:])\n",
    "                            else:\n",
    "                                l[i]['distance_work_2'] = distance_work_2(','.join(address.split(\",\")[x:]))\n",
    "                                written += 1\n",
    "                                break\n",
    "                else:\n",
    "                    passed += 1\n",
    "     \n",
    "                break\n",
    "        \n",
    "            except (googlemaps.exceptions.Timeout, googlemaps.exceptions.TransportError, googlemaps.exceptions.HTTPError) as e:\n",
    "                if a <= 3:\n",
    "                    a += 1\n",
    "                    gmaps = googlemaps.Client(key=gmapsAPI[a_list[a]])\n",
    "                    print \"Changed API key to: \", a_list[a]\n",
    "                else:\n",
    "                    raise GetOutOfLoop\n",
    "    raise GetOutOfLoop\n",
    "                \n",
    "except GetOutOfLoop:\n",
    "    print \"API limits reached\"\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    total_length = len(l.keys())\n",
    "    print \"Minutes: \", total/60\n",
    "    print \"Length of dictionary: \", total_length\n",
    "    print \"Length covered: \", c\n",
    "    print \"Passed: \", passed\n",
    "    print \"Written: \", written \n",
    "    df = df.from_dict(l)\n",
    "    df = df.transpose()\n",
    "    now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "    df.to_csv(\".../gmaps/\"+str(now)+\".csv\",encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to filter down to less than 60 minutes each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = glob.glob('.../gmaps/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file,index_col=0)\n",
    "d4 = df.copy()\n",
    "d4['distance_work_2'] = pd.to_numeric(d4['distance_work_2'])\n",
    "d4['distance_work_1'] = pd.to_numeric(d4['distance_work_1'])\n",
    "d4 = d4[(d4['distance_work_2']<=60)&(d4['distance_work_1']<=60)]\n",
    "d4.shape\n",
    "now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "d4.to_csv(\".../filtered/\"+str(now)+\".csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adds work 2 cycling time\n",
    "\"\"\"\n",
    "\n",
    "# Reads file from previous run\n",
    "list_of_files = glob.glob('.../filtered/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file, index_col=0)\n",
    "df = df.transpose()\n",
    "l = df.to_dict()\n",
    "\n",
    "c = 0\n",
    "written = 0\n",
    "passed = 0\n",
    "\n",
    "a = 0\n",
    "a_list = ['gmaps_API_1', 'gmaps_API_2']\n",
    "gmaps = googlemaps.Client(key=gmapsAPI[a_list[a]])\n",
    "\n",
    "class GetOutOfLoop( Exception ):\n",
    "    pass\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "try:\n",
    "    for i in l.keys():\n",
    "        print c\n",
    "        c+=1\n",
    "        address = l[i]['displayable_address']\n",
    "        length = len(address.split(\",\"))\n",
    "        while True:\n",
    "            try:\n",
    "                if any( [ l[i]['cycling_work_2'] != l[i]['cycling_work_2'], \n",
    "                          'cycling_work_2' not in l[i].keys() ] ):\n",
    "                    for x in range(length):\n",
    "                        try:\n",
    "                            l[i]['cycling_work_2'] = cycling_work_2(','.join(address.split(\",\")[x:]))\n",
    "                        except (googlemaps.exceptions.ApiError, IndexError, TypeError) as e:\n",
    "                            print \"Address failed:          \", ','.join(address.split(\",\")[x:])\n",
    "                        else:\n",
    "                            written += 1\n",
    "                            break\n",
    "\n",
    "                else:\n",
    "                    passed += 1\n",
    "     \n",
    "                break\n",
    "        \n",
    "            except (googlemaps.exceptions.Timeout, googlemaps.exceptions.TransportError, googlemaps.exceptions.HTTPError) as e:\n",
    "                if a <= 3:\n",
    "                    a += 1\n",
    "                    gmaps = googlemaps.Client(key=gmapsAPI[a_list[a]])\n",
    "                    print \"Changed API key to: \", a_list[a]\n",
    "                else:\n",
    "                    raise GetOutOfLoop\n",
    "    raise GetOutOfLoop\n",
    "                \n",
    "except GetOutOfLoop:\n",
    "    print \"API limits reached\"\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    total_length = len(l.keys())\n",
    "    print \"Minutes: \", total/60\n",
    "    print \"Length of dictionary: \", total_length\n",
    "    print \"Length covered: \", c\n",
    "    print \"Passed: \", passed\n",
    "    print \"Written: \", written \n",
    "    df = df.from_dict(l)\n",
    "    df = df.transpose()\n",
    "    now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "    df.to_csv(\".../filtered/\"+str(now)+\"CYCLING.csv\",encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zed Index Area Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keeps running until all from original data have a zed index. Each API key can manage 100/hour so recommended to filter down to only the ones most interested in \n",
    "e.g. Commute times both within a range\n",
    "\"\"\"\n",
    "\n",
    "import zoopla\n",
    "list_of_files = glob.glob('.../filtered/*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file,index_col=0)\n",
    "# df = df.transpose()\n",
    "\n",
    "c = -1\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    c += 1\n",
    "    print c\n",
    "    address = row[\"outcode\"]\n",
    "    if 'zed_index' not in row.keys():\n",
    "        try:\n",
    "            zoop = zoopla.Zoopla(api_key=api['API_1'])\n",
    "            print \"API_1 Row: \",c\n",
    "            zed_index = zoop.zed_index({'area': address,'output_type': 'outcode'})\n",
    "            df.loc[i,\"zed_index\"] = zed_index[\"zed_index\"]\n",
    "            df.loc[i,\"zed_index_3month\"] = zed_index[\"zed_index_3month\"]\n",
    "            df.loc[i,\"zed_index_6month\"] = zed_index[\"zed_index_6month\"]\n",
    "            df.loc[i,\"zed_index_1year\"] = zed_index[\"zed_index_1year\"]\n",
    "            df.loc[i,\"zed_index_2year\"] = zed_index[\"zed_index_2year\"]\n",
    "            df.loc[i,\"zed_index_3year\"] = zed_index[\"zed_index_3year\"]\n",
    "            df.loc[i,\"zed_index_4year\"] = zed_index[\"zed_index_4year\"]\n",
    "            df.loc[i,\"zed_index_5year\"] = zed_index[\"zed_index_5year\"]\n",
    "\n",
    "        except zoopla.exceptions.ZooplaAPIException: \n",
    "            try:\n",
    "                zoop = zoopla.Zoopla(api_key=api['API_2'])\n",
    "                print \"API_2 Row: \",c\n",
    "                zed_index = zoop.zed_index({'area': address,'output_type': 'outcode'})\n",
    "                df.loc[i,\"zed_index\"] = zed_index[\"zed_index\"]\n",
    "                df.loc[i,\"zed_index_3month\"] = zed_index[\"zed_index_3month\"]\n",
    "                df.loc[i,\"zed_index_6month\"] = zed_index[\"zed_index_6month\"]\n",
    "                df.loc[i,\"zed_index_1year\"] = zed_index[\"zed_index_1year\"]\n",
    "                df.loc[i,\"zed_index_2year\"] = zed_index[\"zed_index_2year\"]\n",
    "                df.loc[i,\"zed_index_3year\"] = zed_index[\"zed_index_3year\"]\n",
    "                df.loc[i,\"zed_index_4year\"] = zed_index[\"zed_index_4year\"]\n",
    "                df.loc[i,\"zed_index_5year\"] = zed_index[\"zed_index_5year\"]\n",
    "\n",
    "\n",
    "            except zoopla.exceptions.ZooplaAPIException:\n",
    "                now = datetime.datetime.now()\n",
    "                h = int(now.strftime(\"%H\"))+1\n",
    "                t = now.replace(hour=h,minute=0,second=0)\n",
    "                wait = t - now\n",
    "                print now\n",
    "                print \"Waiting for 60 minutes.\"\n",
    "                sleep(3600)\n",
    "\n",
    "                zoop = zoopla.Zoopla(api_key=api['API_1'])\n",
    "                print \"API_1 Row: \",c\n",
    "                zed_index = zoop.zed_index({'area': address,'output_type': 'outcode'})\n",
    "                df.loc[i,\"zed_index\"] = zed_index[\"zed_index\"]\n",
    "                df.loc[i,\"zed_index_3month\"] = zed_index[\"zed_index_3month\"]\n",
    "                df.loc[i,\"zed_index_6month\"] = zed_index[\"zed_index_6month\"]\n",
    "                df.loc[i,\"zed_index_1year\"] = zed_index[\"zed_index_1year\"]\n",
    "                df.loc[i,\"zed_index_2year\"] = zed_index[\"zed_index_2year\"]\n",
    "                df.loc[i,\"zed_index_3year\"] = zed_index[\"zed_index_3year\"]\n",
    "                df.loc[i,\"zed_index_4year\"] = zed_index[\"zed_index_4year\"]\n",
    "                df.loc[i,\"zed_index_5year\"] = zed_index[\"zed_index_5year\"]\n",
    "    if 'zed_index' in row.keys():\n",
    "        if row[\"zed_index\"] != row[\"zed_index\"]:\n",
    "            try:\n",
    "                zoop = zoopla.Zoopla(api_key=api['API_1'])\n",
    "                print \"API_1 Row: \",c\n",
    "                zed_index = zoop.zed_index({'area': address,'output_type': 'outcode'})\n",
    "                df.loc[i,\"zed_index\"] = zed_index[\"zed_index\"]\n",
    "                df.loc[i,\"zed_index_3month\"] = zed_index[\"zed_index_3month\"]\n",
    "                df.loc[i,\"zed_index_6month\"] = zed_index[\"zed_index_6month\"]\n",
    "                df.loc[i,\"zed_index_1year\"] = zed_index[\"zed_index_1year\"]\n",
    "                df.loc[i,\"zed_index_2year\"] = zed_index[\"zed_index_2year\"]\n",
    "                df.loc[i,\"zed_index_3year\"] = zed_index[\"zed_index_3year\"]\n",
    "                df.loc[i,\"zed_index_4year\"] = zed_index[\"zed_index_4year\"]\n",
    "                df.loc[i,\"zed_index_5year\"] = zed_index[\"zed_index_5year\"]\n",
    "\n",
    "            except zoopla.exceptions.ZooplaAPIException: \n",
    "                try:\n",
    "                    zoop = zoopla.Zoopla(api_key=api['API_2'])\n",
    "                    print \"API_2 Row: \",c\n",
    "                    zed_index = zoop.zed_index({'area': address,'output_type': 'outcode'})\n",
    "                    df.loc[i,\"zed_index\"] = zed_index[\"zed_index\"]\n",
    "                    df.loc[i,\"zed_index_3month\"] = zed_index[\"zed_index_3month\"]\n",
    "                    df.loc[i,\"zed_index_6month\"] = zed_index[\"zed_index_6month\"]\n",
    "                    df.loc[i,\"zed_index_1year\"] = zed_index[\"zed_index_1year\"]\n",
    "                    df.loc[i,\"zed_index_2year\"] = zed_index[\"zed_index_2year\"]\n",
    "                    df.loc[i,\"zed_index_3year\"] = zed_index[\"zed_index_3year\"]\n",
    "                    df.loc[i,\"zed_index_4year\"] = zed_index[\"zed_index_4year\"]\n",
    "                    df.loc[i,\"zed_index_5year\"] = zed_index[\"zed_index_5year\"]\n",
    "\n",
    "\n",
    "                except zoopla.exceptions.ZooplaAPIException:\n",
    "                    now = datetime.datetime.now()\n",
    "                    h = int(now.strftime(\"%H\"))+1\n",
    "                    t = now.replace(hour=h,minute=0,second=0)\n",
    "                    wait = t - now\n",
    "                    print now\n",
    "                    print \"Waiting for 60 minutes.\"\n",
    "                    sleep(3600)\n",
    "\n",
    "                    zoop = zoopla.Zoopla(api_key=api['API_1'])\n",
    "                    print \"API_1 Row: \",c\n",
    "                    zed_index = zoop.zed_index({'area': address,'output_type': 'outcode'})\n",
    "                    df.loc[i,\"zed_index\"] = zed_index[\"zed_index\"]\n",
    "                    df.loc[i,\"zed_index_3month\"] = zed_index[\"zed_index_3month\"]\n",
    "                    df.loc[i,\"zed_index_6month\"] = zed_index[\"zed_index_6month\"]\n",
    "                    df.loc[i,\"zed_index_1year\"] = zed_index[\"zed_index_1year\"]\n",
    "                    df.loc[i,\"zed_index_2year\"] = zed_index[\"zed_index_2year\"]\n",
    "                    df.loc[i,\"zed_index_3year\"] = zed_index[\"zed_index_3year\"]\n",
    "                    df.loc[i,\"zed_index_4year\"] = zed_index[\"zed_index_4year\"]\n",
    "                    df.loc[i,\"zed_index_5year\"] = zed_index[\"zed_index_5year\"]\n",
    "\n",
    "print \"Finished both 10,000 cycles.\"\n",
    "# df = df.transpose()\n",
    "now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "df.to_csv(\".../zedindex/\"+str(now)+\".csv\",encoding='utf-8')\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print \"Time: \", total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many are left\n",
    "\n",
    "# df = df.transpose()\n",
    "df['zed_index'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraper to add extra information such as rental price, area ratings etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions to retrieve data from Zoopla\n",
    "\"\"\"\n",
    "\n",
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns true if the response seems to be HTML, false otherwise\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "def rental_price(d):\n",
    "    num_beds = d['num_bedrooms']\n",
    "    if num_beds == 0:\n",
    "        num_beds = 1\n",
    "    if d['property_type'] == \"Flat\" or d['property_type'] == \"Studio\":\n",
    "        property_type = \"flats\"\n",
    "    else:\n",
    "        property_type = \"houses\"\n",
    "    for x in html.select('td'):\n",
    "        if '/to-rent/'+property_type+'/'+str(num_beds)+'-bedroom' in str(x):\n",
    "            return int(str(x).split(\"\\xa3\")[1].split(\" pcm\")[0].replace(',',''))\n",
    "        \n",
    "def sale_price(d):\n",
    "    num_beds = d['num_bedrooms']\n",
    "    if num_beds == 0:\n",
    "        num_beds = 1\n",
    "    if d['property_type'] == \"Flat\" or d['property_type'] == \"Studio\" or d['property_type'] == \"Block of flats\":\n",
    "        property_type = \"flats\"\n",
    "    else:\n",
    "        property_type = \"houses\"\n",
    "    for x in html.select('td'):\n",
    "        if '/for-sale/'+property_type+'/'+str(num_beds)+'-bedroom' in str(x):\n",
    "            return int(str(x).split(\"\\xa3\")[1].split(\"</strong>\")[0].replace(',',''))\n",
    "        \n",
    "def price_put_on_market():\n",
    "    for x in html.select('p'):\n",
    "        if \"<strong>First listed</strong>\" in str(x):\n",
    "            return int(str(x).split(\"\\xa3\")[1].split(\" on\")[0].replace(',',''))    \n",
    "    \n",
    "def date_put_on_market():\n",
    "    for x in html.select('p'):\n",
    "        if \"<strong>First listed</strong>\" in str(x):\n",
    "            for row in str(x).split(\" on\")[1].splitlines():\n",
    "                if len(row) > 8:\n",
    "                    return row\n",
    "                \n",
    "def page_views():\n",
    "    strong = []\n",
    "    for x in html.select('p'):\n",
    "        if \"<strong>Page views</strong>\" in str(x):\n",
    "            for row in str(x).split(\"days:\")[1].splitlines():\n",
    "                if \"<strong>\" in row:\n",
    "                    strong.append(row.split(\"<strong>\")[1].split(\"</strong>\")[0].replace(',','')) \n",
    "    return strong\n",
    "\n",
    "def local_area_ratings():\n",
    "    stars = []\n",
    "    for x in html.select('li'):\n",
    "        if \"current-rating\" in str(x):\n",
    "            stars.append(float(str(x).split(\"currently \")[1].split(\" stars\")[0]))\n",
    "    return stars\n",
    "\n",
    "def missing_zed_index():\n",
    "    lis = []\n",
    "    c = 0\n",
    "    for x in html.select('span'):\n",
    "        c += 1\n",
    "        if \"js-market-stats-average-value\" in str(x):\n",
    "            lis.append(str(x).split('js-market-stats-average-value\" data-value-all=\"')[1].split(',')[0])\n",
    "    return int(lis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = glob.glob('.../zedindex/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file, index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to parse property listings and pull extra information from property URL.\n",
    "Run again with line 15 and 19 commented out, and 18 uncommented to fill in blocked keys.\n",
    "\"\"\"\n",
    "\n",
    "# Reads file from previous run\n",
    "list_of_files = glob.glob('.../zedindex/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file, index_col=0)\n",
    "df = df.transpose()\n",
    "l = df.to_dict()\n",
    "\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "blocked_keys = [] # Comment out when running to fill in blocked keys\n",
    "print len(l.keys())\n",
    "\n",
    "# for key in blocked_keys:\n",
    "for key in l.keys():\n",
    "    print l[key]['details_url']\n",
    "    print count\n",
    "    count += 1\n",
    "    try:\n",
    "        if 'rental_price' in l[key].keys():\n",
    "            if any( [ l[key]['rental_price'] != l[key]['rental_price'], l[key]['overall_rating'] != l[key]['overall_rating'] ] ):\n",
    "                print \"not equal\"\n",
    "                zoopla = simple_get(l[key]['details_url'])\n",
    "                if zoopla is None:\n",
    "                    raise TypeError\n",
    "                else:\n",
    "                    html = BeautifulSoup(zoopla, 'html.parser')\n",
    "                    l[key]['rental_price'] = rental_price(l[key])\n",
    "                    l[key]['sale_price'] = sale_price(l[key])\n",
    "                    l[key]['price_put_on_market'] = price_put_on_market()\n",
    "                    l[key]['date_put_on_market'] = date_put_on_market()\n",
    "                    l[key]['page_views_30_days'] = int(page_views()[0])\n",
    "                    if len(page_views()) > 1:\n",
    "                        l[key]['page_views_all_time'] = int(page_views()[1])\n",
    "                    l[key]['overall_rating'] = local_area_ratings()[0]\n",
    "                    l[key]['community_and_safety'] = local_area_ratings()[1]\n",
    "                    l[key]['entertainment_and_nightlife'] = local_area_ratings()[2]\n",
    "                    l[key]['parks_and_recreation'] = local_area_ratings()[3]\n",
    "                    l[key]['restaurants_and_shopping'] = local_area_ratings()[4]\n",
    "                    l[key]['schools_and_public_services'] = local_area_ratings()[5]\n",
    "                    l[key]['transport_and_travel'] = local_area_ratings()[6]\n",
    "                    if l[key]['zed_index'] < 1:\n",
    "                        l[key]['zed_index'] = missing_zed_index()\n",
    "                    time.sleep(randrange(100,200)/100.0)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    except TypeError:\n",
    "        try:\n",
    "            print \"Waiting 15 seconds\"\n",
    "            time.sleep(15)\n",
    "            zoopla = simple_get(l[key]['details_url'])\n",
    "            if zoopla is None:\n",
    "                raise TypeError\n",
    "            else:\n",
    "                html = BeautifulSoup(zoopla, 'html.parser')\n",
    "                l[key]['rental_price'] = rental_price(l[key])\n",
    "                l[key]['sale_price'] = sale_price(l[key])\n",
    "                l[key]['price_put_on_market'] = price_put_on_market()\n",
    "                l[key]['date_put_on_market'] = date_put_on_market()\n",
    "                l[key]['page_views_30_days'] = int(page_views()[0])\n",
    "                if len(page_views()) > 1:\n",
    "                    l[key]['page_views_all_time'] = int(page_views()[1])\n",
    "                l[key]['overall_rating'] = local_area_ratings()[0]\n",
    "                l[key]['community_and_safety'] = local_area_ratings()[1]\n",
    "                l[key]['entertainment_and_nightlife'] = local_area_ratings()[2]\n",
    "                l[key]['parks_and_recreation'] = local_area_ratings()[3]\n",
    "                l[key]['restaurants_and_shopping'] = local_area_ratings()[4]\n",
    "                l[key]['schools_and_public_services'] = local_area_ratings()[5]\n",
    "                l[key]['transport_and_travel'] = local_area_ratings()[6]\n",
    "        except TypeError:\n",
    "            print \"Blocked.\"\n",
    "            blocked_keys.append(key)\n",
    "            pass\n",
    "    \n",
    "t1 = time.time()\n",
    "print (t1-t0)/60., \" minutes.\"\n",
    "df = df.from_dict(l)\n",
    "df = df.transpose()\n",
    "now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "df.to_csv(\".../scraper/\"+str(now)+\".csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on zed indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regression on zed indices to find areas of increasing value. Also adds whether auction or not\n",
    "\"\"\"\n",
    "\n",
    "list_of_files = glob.glob('.../scraper/*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file,index_col=0)\n",
    "# df = df.transpose()\n",
    "\n",
    "# Adding columns\n",
    "df[['5_year_reg','4_year_reg','3_year_reg','2_year_reg','1_year_reg','6_month_reg','3_month_reg']] = df[['zed_index_5year','zed_index_4year','zed_index_3year','zed_index_2year','zed_index_1year','zed_index_6month','zed_index_3month']].apply(pd.to_numeric)\n",
    "df['average_sale_price-price'] = df['sale_price'].apply(pd.to_numeric)\n",
    "df['price']=df['price'].apply(pd.to_numeric)\n",
    "df['average_sale_price-price'] = df['sale_price'].sub(df['price'], axis=0 )\n",
    "\n",
    "c = 0\n",
    "drop = 0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    c += 1\n",
    "    #print \"---- NEW -----\"\n",
    "    print c\n",
    "    if float(row['zed_index']) == 0.0:\n",
    "        df.drop(i,inplace=True)\n",
    "        print \"DROP\"\n",
    "        drop += 1\n",
    "    else:\n",
    "        if \"auction\" in row['description']:\n",
    "            df.loc[i,'auction'] = 1\n",
    "        Y = np.array([float(row['zed_index_5year']),float(row['zed_index_4year']),float(row['zed_index_3year']),float(row['zed_index_2year']),float(row['zed_index_1year']),float(row['zed_index_6month']),float(row['zed_index_3month']),float(row['zed_index'])])\n",
    "        X = np.array([0,1,2,3,4,5,5.5,5.75])\n",
    "        X = np.reshape(X,(8,1))\n",
    "        Y = np.reshape(Y,(8,1))\n",
    "        col_names = ['5_year_reg','4_year_reg','3_year_reg','2_year_reg','1_year_reg','6_month_reg','3_month_reg']\n",
    "        col_names_counter = 0\n",
    "        model = LinearRegression()\n",
    "        model.fit(X,Y)\n",
    "#         if float(row['zed_index']) == 0.0:\n",
    "#             continue\n",
    "        df.loc[i,col_names[col_names_counter]] = float(model.coef_[0])/float(row['zed_index'])\n",
    "        col_names_counter += 1\n",
    "        for x in range(len(X)- 2):\n",
    "            X = np.delete(X, 0)\n",
    "            Y = np.delete(Y, 0)\n",
    "            X = np.reshape(X,(8-(x+1),1))\n",
    "            Y = np.reshape(Y,(8-(x+1),1))\n",
    "            model = LinearRegression()\n",
    "            model.fit(X,Y)\n",
    "            df.loc[i,col_names[col_names_counter]] = float(model.coef_[0])/float(row['zed_index'])\n",
    "            col_names_counter += 1\n",
    "        df.loc[i,'1_year_reg_rate'] = (row['1_year_reg'] - row['2_year_reg'])\n",
    "        df.loc[i,'6_month_reg_rate'] = (row['6_month_reg'] - row['1_year_reg'])/2. # Divided by two to regularise for time period of 6 months\n",
    "        df.loc[i,'3_month_reg_rate'] = (row['3_month_reg'] - row['6_month_reg'])/4. # Divided by four to regularise for time period of 3 months\n",
    "\n",
    "# Ordering\n",
    "df = df[['displayable_address','details_url','distance_work_2','distance_work_1','cycling_work_2','agent_name','agent_phone','county','description','first_published_date','last_published_date','latitude','longitude','listing_status','listing_id','num_bathrooms','num_bedrooms','num_recepts','outcode','post_town','property_type','price_put_on_market','page_views_30_days','page_views_all_time','overall_rating','community_and_safety','entertainment_and_nightlife','parks_and_recreation','restaurants_and_shopping','schools_and_public_services','transport_and_travel', 'price', 'rental_price','sale_price', 'average_sale_price-price' ,'zed_index','zed_index_3month','zed_index_6month','zed_index_1year','zed_index_2year','zed_index_3year','zed_index_4year','zed_index_5year','5_year_reg','4_year_reg','3_year_reg','2_year_reg','1_year_reg','6_month_reg','3_month_reg','1_year_reg_rate','6_month_reg_rate','3_month_reg_rate','auction']]\n",
    "print \"Dropped: \",drop\n",
    "now = datetime.datetime.now().strftime(\"%H%M%d%m%y\")\n",
    "df.to_csv(\".../final/\"+str(now)+\".csv\",encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
